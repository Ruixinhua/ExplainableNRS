{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from config.config_utils import set_seed\n",
    "from config.parse_config import ConfigParser\n",
    "from experiment.runner.nc_run import run, init_data_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiAttentionClassifyModel(\n",
      "  (embedding): Embedding(251810, 300)\n",
      "  (classifier): Linear(in_features=300, out_features=15, bias=True)\n",
      "  (final): Linear(in_features=300, out_features=300, bias=True)\n",
      "  (topic_layer): Sequential(\n",
      "    (0): Linear(in_features=300, out_features=2000, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=2000, out_features=100, bias=True)\n",
      "  )\n",
      "  (projection): AttLayer(\n",
      "    (attention): Sequential(\n",
      "      (0): Linear(in_features=300, out_features=128, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "      (3): Flatten(start_dim=1, end_dim=-1)\n",
      "      (4): Softmax(dim=-1)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable params: 76,478,572\n",
      "Freeze params: 0\n",
      "load device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 Loss: 1.0754542350769043: 100%|██████████| 3208/3208 [03:29<00:00, 15.30it/s] \n",
      "100%|██████████| 401/401 [00:05<00:00, 66.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 1\n",
      "    loss           : 1.073741\n",
      "    accuracy       : 0.679257\n",
      "    macro_f        : 0.396104\n",
      "    doc_entropy    : 3.618213\n",
      "    val_loss       : 0.800217\n",
      "    val_accuracy   : 0.738659\n",
      "    val_macro_f    : 0.51498\n",
      "    val_doc_entropy: 4.015196\n",
      "    monitor_best   : 0.738659\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 Loss: 0.8115770220756531: 100%|██████████| 3208/3208 [03:34<00:00, 14.96it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 64.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 2\n",
      "    loss           : 0.722682\n",
      "    accuracy       : 0.762809\n",
      "    macro_f        : 0.560846\n",
      "    doc_entropy    : 4.134907\n",
      "    val_loss       : 0.699033\n",
      "    val_accuracy   : 0.766485\n",
      "    val_macro_f    : 0.577824\n",
      "    val_doc_entropy: 4.268788\n",
      "    monitor_best   : 0.766485\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 Loss: 0.7625419497489929: 100%|██████████| 3208/3208 [03:35<00:00, 14.85it/s] \n",
      "100%|██████████| 401/401 [00:07<00:00, 55.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 3\n",
      "    loss           : 0.63884\n",
      "    accuracy       : 0.786016\n",
      "    macro_f        : 0.597991\n",
      "    doc_entropy    : 4.177661\n",
      "    val_loss       : 0.656384\n",
      "    val_accuracy   : 0.779501\n",
      "    val_macro_f    : 0.601163\n",
      "    val_doc_entropy: 4.085182\n",
      "    monitor_best   : 0.779501\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 Loss: 0.5409938097000122: 100%|██████████| 3208/3208 [03:36<00:00, 14.80it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 64.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 4\n",
      "    loss           : 0.581721\n",
      "    accuracy       : 0.804205\n",
      "    macro_f        : 0.63022\n",
      "    doc_entropy    : 4.076777\n",
      "    val_loss       : 0.629332\n",
      "    val_accuracy   : 0.787841\n",
      "    val_macro_f    : 0.611674\n",
      "    val_doc_entropy: 4.066385\n",
      "    monitor_best   : 0.787841\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 Loss: 0.5164729356765747: 100%|██████████| 3208/3208 [03:36<00:00, 14.84it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 65.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 5\n",
      "    loss           : 0.530042\n",
      "    accuracy       : 0.821147\n",
      "    macro_f        : 0.658462\n",
      "    doc_entropy    : 3.95445\n",
      "    val_loss       : 0.61431\n",
      "    val_accuracy   : 0.794232\n",
      "    val_macro_f    : 0.620323\n",
      "    val_doc_entropy: 3.952786\n",
      "    monitor_best   : 0.794232\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 Loss: 0.3570220172405243: 100%|██████████| 3208/3208 [03:36<00:00, 14.85it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 65.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 6\n",
      "    loss           : 0.484072\n",
      "    accuracy       : 0.836345\n",
      "    macro_f        : 0.683934\n",
      "    doc_entropy    : 3.819045\n",
      "    val_loss       : 0.620367\n",
      "    val_accuracy   : 0.794934\n",
      "    val_macro_f    : 0.62788\n",
      "    val_doc_entropy: 3.789298\n",
      "    monitor_best   : 0.794934\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 7 Loss: 0.15787436068058014: 100%|██████████| 3208/3208 [03:35<00:00, 14.86it/s]\n",
      "100%|██████████| 401/401 [00:06<00:00, 65.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 7\n",
      "    loss           : 0.442091\n",
      "    accuracy       : 0.850375\n",
      "    macro_f        : 0.707219\n",
      "    doc_entropy    : 3.686661\n",
      "    val_loss       : 0.62613\n",
      "    val_accuracy   : 0.793998\n",
      "    val_macro_f    : 0.626108\n",
      "    val_doc_entropy: 3.695529\n",
      "    monitor_best   : 0.794934\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 8 Loss: 0.5448232889175415: 100%|██████████| 3208/3208 [03:36<00:00, 14.85it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 64.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 8\n",
      "    loss           : 0.399342\n",
      "    accuracy       : 0.864589\n",
      "    macro_f        : 0.732997\n",
      "    doc_entropy    : 3.559433\n",
      "    val_loss       : 0.636995\n",
      "    val_accuracy   : 0.794232\n",
      "    val_macro_f    : 0.625663\n",
      "    val_doc_entropy: 3.526581\n",
      "    monitor_best   : 0.794934\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 9 Loss: 0.4767472743988037: 100%|██████████| 3208/3208 [03:35<00:00, 14.89it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 63.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 9\n",
      "    loss           : 0.362917\n",
      "    accuracy       : 0.878433\n",
      "    macro_f        : 0.754278\n",
      "    doc_entropy    : 3.466064\n",
      "    val_loss       : 0.65797\n",
      "    val_accuracy   : 0.792907\n",
      "    val_macro_f    : 0.622639\n",
      "    val_doc_entropy: 3.46579\n",
      "    monitor_best   : 0.794934\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 10 Loss: 0.5627778768539429: 100%|██████████| 3208/3208 [03:37<00:00, 14.75it/s] \n",
      "100%|██████████| 401/401 [00:06<00:00, 64.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 10\n",
      "    loss           : 0.32689\n",
      "    accuracy       : 0.890484\n",
      "    macro_f        : 0.776173\n",
      "    doc_entropy    : 3.371288\n",
      "    val_loss       : 0.679327\n",
      "    val_accuracy   : 0.792673\n",
      "    val_macro_f    : 0.632346\n",
      "    val_doc_entropy: 3.381072\n",
      "    monitor_best   : 0.794934\n",
      "    seed           : 42\n",
      "                   : None\n",
      "    run_name       : News26/keep_all/BiAttentionClassifyModel\n",
      "Validation performance did not improve for 3 epochs. Training stops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from config.configuration import Configuration\n",
    "from config.default_config import arch_default_config\n",
    "\n",
    "arch_type = \"BiAttentionClassifyModel\"\n",
    "kwargs = {\"arch_config\": arch_default_config(arch_type)}\n",
    "config_parser = ConfigParser(Configuration(**kwargs),\n",
    "                             {\"arch_config\": {\"head_num\": 100}, \"optimizer_config\": {\"lr\": 1e-4},\n",
    "                              \"trainer_config\": {\"epochs\": 10}})\n",
    "config = config_parser.config\n",
    "config.update_sub_config(\"data_config\", name=\"MIND15/keep_all\", max_length=512)\n",
    "config.set(\"seed\", 42)\n",
    "data_loader = init_data_loader(config_parser)\n",
    "log = {\"arch_type\": config.arch_config[\"type\"], \"seed\": config.seed,\n",
    "       \"variant_name\": config.arch_config.get(\"variant_name\", None), \"#Voc\": len(data_loader.word_dict)}\n",
    "set_seed(log[\"seed\"])\n",
    "trainer = run(config_parser, data_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from utils import get_topic_dist\n",
    "\n",
    "topic_dist = get_topic_dist(trainer, list(data_loader.word_dict.values())).transpose(1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "id2word = {k: w for w, k in data_loader.word_dict.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #10000 to Dictionary(76864 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #20000 to Dictionary(103270 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #30000 to Dictionary(122908 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #40000 to Dictionary(139266 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #50000 to Dictionary(153076 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #60000 to Dictionary(165969 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #70000 to Dictionary(177578 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #80000 to Dictionary(188413 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #90000 to Dictionary(198849 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #100000 to Dictionary(208342 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #110000 to Dictionary(217766 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "adding document #120000 to Dictionary(226614 unique tokens: [\"'\", '(', ')', ',', '-']...)\n",
      "built Dictionary(233314 unique tokens: [\"'\", '(', ')', ',', '-']...) from 128303 documents (total 82004758 corpus positions)\n",
      "Dictionary lifecycle event {'msg': 'built Dictionary(233314 unique tokens: [\"\\'\", \\'(\\', \\')\\', \\',\\', \\'-\\']...) from 128303 documents (total 82004758 corpus positions)', 'datetime': '2022-02-23T23:05:11.525718', 'gensim': '4.1.2', 'python': '3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "discarding 199576 tokens: [(\"'\", 95060), ('(', 65440), (')', 65480), (',', 121209), ('-', 108258), ('.', 127584), ('0', 98912), ('1', 101124), ('2', 96913), ('3', 75045)]...\n",
      "keeping 33738 tokens which were in no less than 30 and no more than 64151 (=50.0%) documents\n",
      "resulting dictionary: Dictionary(33738 unique tokens: ['6', 'about', 'according', 'affect', 'affected']...)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'@'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20356/3616686624.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mref_texts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_docs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mtopic_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfilter_tokens\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mref_texts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m30\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mtopic_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mdata_loader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtopic_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_20356/3616686624.py\u001B[0m in \u001B[0;36m<dictcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mref_texts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_docs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset_name\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmethod\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mtopic_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfilter_tokens\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mref_texts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m30\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[0mtopic_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mdata_loader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mword_dict\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtoken\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mtoken\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtopic_dict\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m: '@'"
     ]
    }
   ],
   "source": [
    "from utils import load_docs, filter_tokens\n",
    "dataset_name, method = config.data_config[\"name\"].split(\"/\")\n",
    "ref_texts = load_docs(dataset_name, method)\n",
    "topic_dict = filter_tokens(ref_texts, 30, 0.5)\n",
    "word_index = [data_loader.word_dict[w] for w in topic_dict.values() if w in data_loader.word_dict]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "word_graph = []\n",
    "threshold = 0.8\n",
    "for i in range(1, topic_dist.shape[0]):\n",
    "    cos_simi = cosine_similarity(topic_dist[i].reshape(1, -1), topic_dist[i:])[0]\n",
    "    for j in range(len(cos_simi)):\n",
    "        if cos_simi[j] > threshold:\n",
    "            word_graph.append((i, i+j))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from utils import get_project_root, read_json\n",
    "from utils.graph_untils import load_entities\n",
    "\n",
    "entity2id = load_entities()\n",
    "default_config = read_json(Path(get_project_root()) / \"config\" / \"mind_rs_default.json\")\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "\n",
    "def load_news_entity_from_file(news_file):\n",
    "    news_entity = defaultdict()\n",
    "    with open(news_file, \"r\", encoding=\"utf-8\") as rd:\n",
    "        for text in rd:\n",
    "            # news id, category, subcategory, title, abstract, url\n",
    "            nid, vert, subvert, title, abstract, url, title_entity, abs_entity = text.strip(\"\\n\").split(\"\\t\")\n",
    "            title_entity_json, abstract_entity_json = json.loads(title_entity), json.loads(abs_entity)\n",
    "            for entity in title_entity_json + abstract_entity_json:\n",
    "                news_entity[entity[\"WikidataId\"]] = entity[\"SurfaceForms\"]\n",
    "    return news_entity\n",
    "\n",
    "\n",
    "root_path = Path(default_config[\"data_config\"][\"data_path\"])\n",
    "news_entities = defaultdict()\n",
    "phases = [\"train\", \"valid\", \"test\"]\n",
    "mind_type = \"large\"\n",
    "for phase in phases:\n",
    "    file = root_path / mind_type / phase / \"news.tsv\"\n",
    "    if file.exists():\n",
    "        news_entities.update(load_news_entity_from_file(file))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}